{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Here is a short cheat sheet for the tasks you mentioned, using Python:\n",
    "\n",
    "**2.1 Perform standard data import, joining and aggregation tasks**\n",
    "\n",
    "- Import data from flat files into Python:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('file.csv')\n",
    "```\n",
    "\n",
    "- Import data from databases into Python:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///database.db')\n",
    "data = pd.read_sql('SELECT * FROM table', engine)\n",
    "```\n",
    "\n",
    "- Aggregate numeric, categorical variables and dates by groups:\n",
    "\n",
    "```python\n",
    "grouped_data = data.groupby('group_column').agg({'numeric_column': 'mean', 'date_column': 'max'})\n",
    "```\n",
    "\n",
    "- Combine multiple tables by rows or columns:\n",
    "\n",
    "```python\n",
    "# By rows\n",
    "combined_data = pd.concat([data1, data2])\n",
    "\n",
    "# By columns\n",
    "combined_data = pd.concat([data1, data2], axis=1)\n",
    "```\n",
    "\n",
    "- Filter data based on different criteria:\n",
    "\n",
    "```python\n",
    "filtered_data = data[data['column'] > value]\n",
    "```\n",
    "\n",
    "**2.2 Perform standard cleaning tasks to prepare data for analysis**\n",
    "\n",
    "- Match strings in a dataset with specific patterns:\n",
    "\n",
    "```python\n",
    "matched_data = data[data['column'].str.contains('pattern')]\n",
    "```\n",
    "\n",
    "- Convert values between data types:\n",
    "\n",
    "```python\n",
    "data['column'] = data['column'].astype('int')\n",
    "```\n",
    "\n",
    "- Clean categorical and text data by manipulating strings:\n",
    "\n",
    "```python\n",
    "data['column'] = data['column'].str.lower().str.strip()\n",
    "```\n",
    "\n",
    "- Clean date and time data:\n",
    "\n",
    "```python\n",
    "data['date_column'] = pd.to_datetime(data['date_column'])\n",
    "```\n",
    "\n",
    "**2.3 Assess data quality and perform validation tasks**\n",
    "\n",
    "- Identify and replace missing values:\n",
    "\n",
    "```python\n",
    "data['column'].fillna(value, inplace=True)\n",
    "```\n",
    "\n",
    "- Perform different types of data validation tasks:\n",
    "\n",
    "```python\n",
    "# Consistency\n",
    "assert data['column'].notnull().all()\n",
    "\n",
    "# Constraints\n",
    "assert (data['column'] > 0).all()\n",
    "\n",
    "# Range validation\n",
    "assert data['column'].between(min_value, max_value).all()\n",
    "\n",
    "# Uniqueness\n",
    "assert data['column'].is_unique\n",
    "```\n",
    "\n",
    "- Identify and validate data types in a data set:\n",
    "\n",
    "```python\n",
    "assert data['column'].dtype == 'int'\n",
    "```\n",
    "\n",
    "**2.4 Collect data from non-standard formats by modifying existing code**\n",
    "\n",
    "- Adapt provided code to import data from an API:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://api.url')\n",
    "data = response.json()\n",
    "```\n",
    "\n",
    "- Identify the structure of HTML and JSON data and parse them into a usable format:\n",
    "\n",
    "```python\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# JSON\n",
    "data = json.loads(json_string)\n",
    "\n",
    "# HTML\n",
    "soup = BeautifulSoup(html_string, 'html.parser')\n",
    "```\n",
    "\n",
    "Please note that these are basic examples and might need to be adjusted based on your specific use case."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6bbdbec08de5d645"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is a short cheat sheet for the tasks you mentioned, using Python:\n",
    "\n",
    "**3.1 Prepare data for modeling by implementing relevant transformations**\n",
    "\n",
    "- Create new features from existing data:\n",
    "\n",
    "```python\n",
    "# Creating categories from continuous data\n",
    "data['category'] = pd.cut(data['continuous_column'], bins=3, labels=['low', 'medium', 'high'])\n",
    "\n",
    "# Combining variables with external data\n",
    "data = pd.merge(data, external_data, on='common_column')\n",
    "```\n",
    "\n",
    "- Importance of splitting data: Splitting data into training, testing, and validation sets allows us to train our model on one set of data (training set), tune our model's hyperparameters with another set (validation set), and then test our model's performance on unseen data (test set).\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "- Importance of scaling data: Scaling data is important because many machine learning algorithms perform better when numerical input variables are scaled to a standard range.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "- Transform categorical data for modeling:\n",
    "\n",
    "```python\n",
    "data = pd.get_dummies(data, columns=['categorical_column'])\n",
    "```\n",
    "\n",
    "**3.2 Implement standard modeling approaches for supervised learning problems**\n",
    "\n",
    "- Identify regression problems and implement models:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "- Identify classification problems and implement models:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "**3.3 Implement approaches for unsupervised learning problems**\n",
    "\n",
    "- Identify clustering problems and implement approaches:\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "```\n",
    "\n",
    "- Explain dimensionality reduction techniques and implement the techniques:\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "```\n",
    "\n",
    "**3.4 Use suitable methods to assess the performance of a model**\n",
    "\n",
    "- Select metrics to evaluate regression models and calculate the metrics:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "```\n",
    "\n",
    "- Select metrics to evaluate classification models and calculate the metrics:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "```\n",
    "\n",
    "- Select metrics and visualizations to evaluate clustering models:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "score = silhouette_score(X, kmeans.labels_)\n",
    "```\n",
    "\n",
    "Please note that these are basic examples and might need to be adjusted based on your specific use case."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11760bf0dedd1b63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4.1 Use common programming constructs to write repeatable production quality code for analysis**\n",
    "\n",
    "- Define, write and execute functions in Python:\n",
    "\n",
    "```python\n",
    "def add_numbers(a, b):\n",
    "    return a + b\n",
    "\n",
    "result = add_numbers(5, 7)\n",
    "```\n",
    "\n",
    "- Use and write control flow statements in Python:\n",
    "\n",
    "```python\n",
    "if result > 10:\n",
    "    print(\"Result is greater than 10\")\n",
    "else:\n",
    "    print(\"Result is less than or equal to 10\")\n",
    "```\n",
    "\n",
    "- Use and write loops and iterations in Python:\n",
    "\n",
    "```python\n",
    "for i in range(10):\n",
    "    print(i)\n",
    "```\n",
    "\n",
    "**4.2 Demonstrates best practices in production code including version control, testing, and package development**\n",
    "\n",
    "- Basic flow and structures of package development in Python:\n",
    "\n",
    "    1. Create a directory for the package.\n",
    "    2. Inside this directory, create an `__init__.py` file.\n",
    "    3. Add your modules and scripts to this directory.\n",
    "    4. Optionally, add a `setup.py` file for package requirements.\n",
    "\n",
    "- Documenting code in packages, or modules in Python:\n",
    "\n",
    "```python\n",
    "def add_numbers(a, b):\n",
    "    \"\"\"\n",
    "    This function adds two numbers together.\n",
    "    \n",
    "    Parameters:\n",
    "    a (int): The first number\n",
    "    b (int): The second number\n",
    "\n",
    "    Returns:\n",
    "    int: The sum of a and b\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "```\n",
    "\n",
    "- Importance of testing and writing testing statements in Python:\n",
    "\n",
    "Testing is important to ensure your code behaves as expected. Here's a simple test using the `assert` statement:\n",
    "\n",
    "```python\n",
    "def test_add_numbers():\n",
    "    assert add_numbers(2, 3) == 5\n",
    "```\n",
    "\n",
    "- Importance of version control and key concepts of versioning:\n",
    "\n",
    "Version control is important for tracking changes, collaborating, and maintaining the history of your code. Key concepts include commits (saving changes), branches (isolating changes for specific features), and merges (combining changes from different branches)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "583115e68a020df5"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c4593b510c97775f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sure, here's a short cheat sheet for using the `pivot_table()` function in Python with the pandas library:\n",
    "\n",
    "- Basic usage of `pivot_table()`:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame and 'index_column', 'column' and 'values_column' are column names in 'df'\n",
    "pivot_table = df.pivot_table(index='index_column', columns='column', values='values_column')\n",
    "```\n",
    "\n",
    "- Using `pivot_table()` with multiple index columns:\n",
    "\n",
    "```python\n",
    "pivot_table = df.pivot_table(index=['index_column1', 'index_column2'], columns='column', values='values_column')\n",
    "```\n",
    "\n",
    "- Using `pivot_table()` with multiple columns:\n",
    "\n",
    "```python\n",
    "pivot_table = df.pivot_table(index='index_column', columns=['column1', 'column2'], values='values_column')\n",
    "```\n",
    "\n",
    "- Using `pivot_table()` with multiple values columns:\n",
    "\n",
    "```python\n",
    "pivot_table = df.pivot_table(index='index_column', columns='column', values=['values_column1', 'values_column2'])\n",
    "```\n",
    "\n",
    "- Using `pivot_table()` with an aggregation function:\n",
    "\n",
    "```python\n",
    "pivot_table = df.pivot_table(index='index_column', columns='column', values='values_column', aggfunc='mean')\n",
    "```\n",
    "\n",
    "- Filling missing values in the pivot table:\n",
    "\n",
    "```python\n",
    "pivot_table = df.pivot_table(index='index_column', columns='column', values='values_column', fill_value=0)\n",
    "```\n",
    "\n",
    "Please replace `'df'`, `'index_column'`, `'column'`, and `'values_column'` with your actual DataFrame and column names."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddb16eceb8194114"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sure, here's a short cheat sheet entry for using the confusion matrix to judge model predictive power in Python:\n",
    "\n",
    "- Import the necessary library:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "```\n",
    "\n",
    "- Generate predictions from your model:\n",
    "\n",
    "```python\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "- Create the confusion matrix:\n",
    "\n",
    "```python\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "```\n",
    "\n",
    "- Interpret the confusion matrix:\n",
    "\n",
    "The confusion matrix `cm` is a 2x2 matrix (for binary classification problems) where:\n",
    "\n",
    "    - `cm[0,0]` is the number of true negatives (TN)\n",
    "    - `cm[0,1]` is the number of false positives (FP)\n",
    "    - `cm[1,0]` is the number of false negatives (FN)\n",
    "    - `cm[1,1]` is the number of true positives (TP)\n",
    "\n",
    "These values can be used to calculate further metrics such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "Please replace `'model'`, `'X_test'`, and `'y_test'` with your actual model and test data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1f7e4c177fce956"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sure, here's a short cheat sheet entry for accuracy, precision, recall, and F1 score in Python:\n",
    "\n",
    "- Accuracy: It is the ratio of correctly predicted observations to the total observations.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "```\n",
    "\n",
    "- Precision: It is the ratio of correctly predicted positive observations to the total predicted positive observations.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred)\n",
    "```\n",
    "\n",
    "- Recall (Sensitivity): It is the ratio of correctly predicted positive observations to the all observations in actual class.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall = recall_score(y_test, y_pred)\n",
    "```\n",
    "\n",
    "- F1 Score: It is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account.\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "```\n",
    "\n",
    "Please replace `'y_test'` and `'y_pred'` with your actual test labels and predicted labels respectively."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cce9af8f5b7d5fb4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
